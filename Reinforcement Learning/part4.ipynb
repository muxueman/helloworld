{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9V-Rn_atzVm8"
   },
   "source": [
    "#ELEN 6885 Reinforcement Learning Coding Assignment (Part 4)#\n",
    "There are a lot of official and unofficial tutorials about Tensorflow, and there are also many open-source projects written in Tensorflow. You can refer to those resources according to your interest. In this part of homework 4, only knowledge of Deep Reinforcement Learning and basic programming skills will be needed.\n",
    "\n",
    "Please put your code into the block marked by\\\n",
    "\\############################\\\n",
    "\\# YOUR CODE STARTS HERE\\\n",
    "\\# YOUR CODE ENDS HERE\\\n",
    "\\############################\\\n",
    "Normally you don't need to edit anything outside of the block. If you do want to edit something, please use a similar manner to mark you edits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#from tensorflow.python.framework import ops\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 64
    },
    "colab_type": "code",
    "id": "DESXLxAP9fLI",
    "outputId": "97271fbd-b794-4734-e3b1-4f73e220a34d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# DQN\n",
    "class DQN:\n",
    "    def __init__(\n",
    "        self,\n",
    "        actions_num,\n",
    "        state_size,\n",
    "        learning_rate = 0.001,\n",
    "        gamma = 0.99,\n",
    "        epsilon_min = 0.05,\n",
    "        epsilon_start = 0.9,\n",
    "        replace_target_iter = 300,\n",
    "        memory_size = 500,\n",
    "        batch_size = 2,\n",
    "        epsilon_increment = None,\n",
    "    ):\n",
    "        self.actions_num = actions_num\n",
    "        self.state_size = state_size\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = gamma\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.replace_target_iter = replace_target_iter\n",
    "        self.memory_size = memory_size\n",
    "        self.batch_size = batch_size\n",
    "        self.epsilon_increment = epsilon_increment\n",
    "        self.epsilon = epsilon_start if epsilon_increment is not None else self.epsilon_min\n",
    "        self.save_model_path = './weights/DQN_model.ckpt'\n",
    "        self.memory_counter = 0\n",
    "        # learned steps counter\n",
    "        self.steps_counter = 0\n",
    "        # initialize memory [s, a, r, s_, done]\n",
    "        self.memory = np.zeros((self.memory_size, state_size * 2 + 3))\n",
    "        # build target_net and q_net\n",
    "        self.build_net()\n",
    "        t_params = tf.get_collection('target_net_params')\n",
    "        q_params = tf.get_collection('q_net_params')\n",
    "        self.replace_target = [tf.assign(t, q) for t, q in zip(t_params, q_params)]\n",
    "      # gpu setting\n",
    "        config = tf.ConfigProto(log_device_placement=False, allow_soft_placement=True)\n",
    "        config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "        self.sess = tf.Session(config=config)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    def build_net(self):\n",
    "      # build q_net\n",
    "            self.state = tf.placeholder(tf.float32, [None, self.state_size], name='state')\n",
    "            self.q_target = tf.placeholder(tf.float32, [None, self.actions_num], name='Q_target')     \n",
    "            with tf.variable_scope('q_net'):\n",
    "      # c_names(collections_names) are the collections to store variables\n",
    "                c_names, neurons_layer_1, w_initializer, b_initializer = \\\n",
    "                ['q_net_params', tf.GraphKeys.GLOBAL_VARIABLES], 100, \\\n",
    "                tf.random_normal_initializer(0., 0.3), tf.constant_initializer(0.1)\n",
    "      # layer 1\n",
    "                with tf.variable_scope('layer_1'):\n",
    "                    w_layer_1 = tf.get_variable('w_layer_1', [self.state_size, neurons_layer_1], initializer=w_initializer, collections=c_names)\n",
    "                    b_layer_1 = tf.get_variable('b_layer_1', [1, neurons_layer_1], initializer=b_initializer, collections=c_names)\n",
    "                    layer_1 = tf.nn.relu(tf.matmul(self.state, w_layer_1) + b_layer_1)\n",
    "      # layer 2\n",
    "                with tf.variable_scope('layer_2'):\n",
    "                    w_layer_2 = tf.get_variable('w_layer_2', [neurons_layer_1, self.actions_num], initializer=w_initializer, collections=c_names)\n",
    "                    b_layer_2 = tf.get_variable('b_layer_2', [1, self.actions_num], initializer=b_initializer, collections=c_names)\n",
    "                    self.q_value = tf.matmul(layer_1, w_layer_2) + b_layer_2\n",
    "            with tf.variable_scope('loss'):\n",
    "                self.loss = tf.reduce_mean(tf.squared_difference(self.q_target, self.q_value))\n",
    "            with tf.variable_scope('train'):\n",
    "                self._train_op = tf.train.AdamOptimizer(self.lr).minimize(self.loss)\n",
    "\n",
    "    # build target_net\n",
    "            self.state_t = tf.placeholder(tf.float32, [None, self.state_size], name='state_t')    # input\n",
    "            with tf.variable_scope('target_net'):\n",
    "      # c_names(collections_names) are the collections to store variables\n",
    "                c_names = ['target_net_params', tf.GraphKeys.GLOBAL_VARIABLES]\n",
    "      # layer 1\n",
    "                with tf.variable_scope('layer_1'):\n",
    "                    w_layer_1 = tf.get_variable('w_layer_1', [self.state_size, neurons_layer_1], initializer=w_initializer, collections=c_names)\n",
    "                    b_layer_1 = tf.get_variable('b_layer_1', [1, neurons_layer_1], initializer=b_initializer, collections=c_names)\n",
    "                    layer_1 = tf.nn.relu(tf.matmul(self.state_t, w_layer_1) + b_layer_1)\n",
    "      # layer 2    \n",
    "                with tf.variable_scope('layer_2'):\n",
    "                    w_layer_2 = tf.get_variable('w_layer_2', [neurons_layer_1, self.actions_num], initializer=w_initializer, collections=c_names)\n",
    "                    b_layer_2 = tf.get_variable('b_layer_2', [1, self.actions_num], initializer=b_initializer, collections=c_names)\n",
    "                    self.q_next = tf.matmul(layer_1, w_layer_2) + b_layer_2\n",
    "            \n",
    "   \n",
    "     \n",
    "    def store_transition(self, s, a, r, s_, done):\n",
    "        s=s.reshape(-1)\n",
    "        s_=s_.reshape(-1)\n",
    "        transition = np.hstack((s, [a, r], s_, done))\n",
    "\n",
    "    # replace the old memory with new observations\n",
    "        index = self.memory_counter % self.memory_size\n",
    "        self.memory[index, :] = transition\n",
    "\n",
    "        self.memory_counter += 1\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "    # to have batch dimension when fed into tf placeholder\n",
    "        observation = observation[np.newaxis, :]\n",
    "    # epsilon-greedy\n",
    "        if np.random.uniform() > self.epsilon:\n",
    "            action_values = self.sess.run(self.q_value, feed_dict={self.state: observation})\n",
    "            action = np.argmax(action_values)\n",
    "        else:\n",
    "            action = np.random.randint(0, self.actions_num)\n",
    "        return action\n",
    "\n",
    "    def learn(self):\n",
    "    # replace target parameters every once a while\n",
    "        if self.steps_counter % self.replace_target_iter == 0:\n",
    "            self.sess.run(self.replace_target)\n",
    "\n",
    "    # sample a batch from the memory\n",
    "        if self.memory_counter > self.memory_size:\n",
    "            sample_index = np.random.choice(self.memory_size, size=self.batch_size)\n",
    "        else:\n",
    "            sample_index = np.random.choice(self.memory_counter, size=self.batch_size)\n",
    "        batch_memory = self.memory[sample_index, :]\n",
    "\n",
    "        q_next, q_value = self.sess.run(\n",
    "            [self.q_next, self.q_value],\n",
    "            feed_dict={\n",
    "                self.state_t: batch_memory[:, -self.state_size-1:-1],  # fixed params\n",
    "                self.state: batch_memory[:, :self.state_size],  # newest params\n",
    "          })\n",
    "\n",
    "    # calculate q_target\n",
    "        q_target = q_value.copy()\n",
    "\n",
    "    # only change the action-values of this batch, because we only calculate loss on the batch observations\n",
    "        batch_index = np.arange(self.batch_size, dtype=np.int32)\n",
    "        act_index = batch_memory[:, self.state_size].astype(int)\n",
    "        reward = batch_memory[:, self.state_size + 1]\n",
    "        done = batch_memory[:, -1]\n",
    "    ############################\n",
    "    \n",
    "        for batch_idx in batch_index:\n",
    "            A = act_index[batch_idx]\n",
    "            R = reward[batch_idx]\n",
    "            Done = done[batch_idx]\n",
    "            if Done:\n",
    "                q_target[batch_idx,A] = R\n",
    "            else:\n",
    "                q_target[batch_idx,A] = R + self.gamma*np.max(q_next[batch_idx])\n",
    "                \n",
    "    ############################\n",
    "    \n",
    "    # train q_net\n",
    "        _, self.cost = self.sess.run([self._train_op, self.loss],\n",
    "                                  feed_dict={self.state: batch_memory[:, :self.state_size],\n",
    "                                            self.q_target: q_target})\n",
    "    # change epsilon\n",
    "        self.epsilon = self.epsilon - self.epsilon_increment if self.epsilon > self.epsilon_min else self.epsilon_min\n",
    "        self.steps_counter += 1\n",
    "\n",
    "    def store(self):\n",
    "        saver = tf.train.Saver() \n",
    "        saver.save(self.sess, self.save_model_path)\n",
    "  \n",
    "    def restore(self):\n",
    "        saver = tf.train.Saver() \n",
    "        saver.restore(self.sess, self.save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "R_Pan2x1XlxB",
    "outputId": "c7d720f0-dcbc-4f1a-d5ad-b84459fda9c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(2)\n",
      "Box(4,)\n",
      "(array([-1.77097534e-02,  2.33842555e-01, -9.75710380e-05, -2.80948637e-01]), 1.0, False, {})\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "# cart pole gym environment\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "env._max_episode_steps = 500\n",
    "# state and action space\n",
    "print(env.action_space)\n",
    "print(env.observation_space)\n",
    "# observation\n",
    "env.reset()\n",
    "# state, reward, done, info\n",
    "print(env.step(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UMOz0IC6cJqt"
   },
   "outputs": [],
   "source": [
    "# play the game and train the network\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "episode_length_set = []\n",
    "tf.reset_default_graph()\n",
    "total_time_steps = 100000\n",
    "\n",
    "RL = DQN(actions_num = 2, gamma = 0.99,\n",
    "         state_size = 4, epsilon_start = 1,\n",
    "         learning_rate = 1e-3, epsilon_min = 0.01,\n",
    "         replace_target_iter = 100, memory_size = 5000,\n",
    "         epsilon_increment = 0.00001,)\n",
    "\n",
    "new_state = env.reset()\n",
    "done = False\n",
    "episode_length_counter = 0\n",
    "for step in range(total_time_steps):\n",
    "    \n",
    "  ############################\n",
    "  \n",
    "    observation = new_state\n",
    "    action = RL.choose_action(observation)\n",
    "    observation_, reward, done,_ = env.step(action)\n",
    "    RL.store_transition(observation, action, reward, observation_, done)\n",
    "    \n",
    "    if done:\n",
    "        new_state = env.reset()\n",
    "        episode_length_set.append(episode_length_counter+1)\n",
    "        episode_length_counter = 0\n",
    "    else:\n",
    "        new_state = observation_\n",
    "              \n",
    "  ############################  \n",
    "    if step > 200:\n",
    "        RL.learn()\n",
    "    episode_length_counter += 1  \n",
    "    if episode_length_counter == 500:\n",
    "        RL.store()\n",
    "        \n",
    "RL.store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LCxAuNQegi2Q"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x215c5259cf8>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x215c4bec898>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(episode_length_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "KF1UKCM3rp4m",
    "outputId": "94076fef-765c-4d57-fba2-eb1714d6666c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./weights/DQN_model.ckpt\n",
      "Trail:  1  Agent time:  372\n",
      "Trail:  2  Agent time:  455\n",
      "Trail:  3  Agent time:  387\n",
      "Trail:  4  Agent time:  456\n",
      "Trail:  5  Agent time:  380\n",
      "Trail:  6  Agent time:  425\n",
      "Trail:  7  Agent time:  456\n",
      "Trail:  8  Agent time:  402\n",
      "Trail:  9  Agent time:  378\n",
      "Trail:  10  Agent time:  435\n",
      "Trail:  11  Agent time:  383\n",
      "Trail:  12  Agent time:  423\n",
      "Trail:  13  Agent time:  341\n",
      "Trail:  14  Agent time:  427\n",
      "Trail:  15  Agent time:  399\n",
      "Trail:  16  Agent time:  422\n",
      "Trail:  17  Agent time:  468\n",
      "Trail:  18  Agent time:  380\n",
      "Trail:  19  Agent time:  377\n",
      "Trail:  20  Agent time:  452\n",
      "Trail:  21  Agent time:  382\n",
      "Trail:  22  Agent time:  376\n",
      "Trail:  23  Agent time:  339\n",
      "Trail:  24  Agent time:  392\n",
      "Trail:  25  Agent time:  428\n",
      "Trail:  26  Agent time:  455\n",
      "Trail:  27  Agent time:  450\n",
      "Trail:  28  Agent time:  452\n",
      "Trail:  29  Agent time:  373\n",
      "Trail:  30  Agent time:  395\n",
      "Trail:  31  Agent time:  379\n",
      "Trail:  32  Agent time:  428\n",
      "Trail:  33  Agent time:  412\n",
      "Trail:  34  Agent time:  452\n",
      "Trail:  35  Agent time:  436\n",
      "Trail:  36  Agent time:  472\n",
      "Trail:  37  Agent time:  466\n",
      "Trail:  38  Agent time:  357\n",
      "Trail:  39  Agent time:  393\n",
      "Trail:  40  Agent time:  382\n",
      "Trail:  41  Agent time:  364\n",
      "Trail:  42  Agent time:  434\n",
      "Trail:  43  Agent time:  302\n",
      "Trail:  44  Agent time:  407\n",
      "Trail:  45  Agent time:  403\n",
      "Trail:  46  Agent time:  306\n",
      "Trail:  47  Agent time:  402\n",
      "Trail:  48  Agent time:  340\n",
      "Trail:  49  Agent time:  452\n",
      "Trail:  50  Agent time:  371\n",
      "Trail:  51  Agent time:  317\n",
      "Trail:  52  Agent time:  454\n",
      "Trail:  53  Agent time:  376\n",
      "Trail:  54  Agent time:  428\n",
      "Trail:  55  Agent time:  402\n",
      "Trail:  56  Agent time:  442\n",
      "Trail:  57  Agent time:  461\n",
      "Trail:  58  Agent time:  452\n",
      "Trail:  59  Agent time:  421\n",
      "Trail:  60  Agent time:  381\n",
      "Trail:  61  Agent time:  406\n",
      "Trail:  62  Agent time:  414\n",
      "Trail:  63  Agent time:  426\n",
      "Trail:  64  Agent time:  408\n",
      "Trail:  65  Agent time:  443\n",
      "Trail:  66  Agent time:  352\n",
      "Trail:  67  Agent time:  397\n",
      "Trail:  68  Agent time:  430\n",
      "Trail:  69  Agent time:  372\n",
      "Trail:  70  Agent time:  357\n",
      "Trail:  71  Agent time:  335\n",
      "Trail:  72  Agent time:  419\n",
      "Trail:  73  Agent time:  373\n",
      "Trail:  74  Agent time:  411\n",
      "Trail:  75  Agent time:  443\n",
      "Trail:  76  Agent time:  416\n",
      "Trail:  77  Agent time:  430\n",
      "Trail:  78  Agent time:  468\n",
      "Trail:  79  Agent time:  379\n",
      "Trail:  80  Agent time:  441\n",
      "Trail:  81  Agent time:  421\n",
      "Trail:  82  Agent time:  326\n",
      "Trail:  83  Agent time:  402\n",
      "Trail:  84  Agent time:  314\n",
      "Trail:  85  Agent time:  403\n",
      "Trail:  86  Agent time:  367\n",
      "Trail:  87  Agent time:  373\n",
      "Trail:  88  Agent time:  346\n",
      "Trail:  89  Agent time:  475\n",
      "Trail:  90  Agent time:  405\n",
      "Trail:  91  Agent time:  420\n",
      "Trail:  92  Agent time:  473\n",
      "Trail:  93  Agent time:  465\n",
      "Trail:  94  Agent time:  421\n",
      "Trail:  95  Agent time:  454\n",
      "Trail:  96  Agent time:  385\n",
      "Trail:  97  Agent time:  404\n",
      "Trail:  98  Agent time:  408\n",
      "Trail:  99  Agent time:  398\n",
      "Trail:  100  Agent time:  352\n"
     ]
    }
   ],
   "source": [
    "# test our network\n",
    "tf.reset_default_graph()\n",
    "RL = DQN(actions_num = 2, gamma = 1,\n",
    "         state_size = 4, epsilon_start = 1,\n",
    "         learning_rate = 1e-3, epsilon_min = 0,\n",
    "         replace_target_iter = 100, memory_size = 5000,\n",
    "         epsilon_increment = None,)\n",
    "# load saved parameters\n",
    "RL.restore()\n",
    "# run 100 trails and print how long can the agent hold the cart pole for each trail\n",
    "for i in range(100):\n",
    "  ############################\n",
    "  \n",
    "    new_state = env.reset()\n",
    "    done = False\n",
    "    episode_length_counter = 0\n",
    "    while True:\n",
    "        observation = new_state\n",
    "        action = RL.choose_action(observation)\n",
    "        observation_, reward, done,_ = env.step(action)\n",
    "        episode_length_counter += 1\n",
    "        new_state = observation_ \n",
    "        if done:\n",
    "            break\n",
    "    print('Trail: ', i+1, ' Agent time: ', episode_length_counter)\n",
    " \n",
    "  ############################\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gxhwfe303YhK"
   },
   "source": [
    "You may find that the episode length doesn't stably improve as more training time is given. You can read chapter 3.2 of this paper https://arxiv.org/pdf/1711.07478.pdf if you are interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ELEN 6885 HW4 Part 4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
